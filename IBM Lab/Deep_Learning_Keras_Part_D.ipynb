{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLkKpgV63d7p"
      },
      "source": [
        "\n",
        "### Deep_Learning_Keras_Part_D Sumbission\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMsEyU3vw9uw"
      },
      "source": [
        "### import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkLlsLYpw9uy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4PTjglIWw9u0",
        "outputId": "e81067b6-0e46-48b9-e1a1-4caf1fbc63d6"
      },
      "outputs": [],
      "source": [
        "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
        "concrete_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73Lv31Bpw9u1"
      },
      "source": [
        "### To check how many data points we have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBUqxeO8w9u1",
        "outputId": "742bc65b-87ff-400b-9e23-6d58f98e5d78"
      },
      "outputs": [],
      "source": [
        "concrete_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQymHIRw9u1"
      },
      "source": [
        "### Generate descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset's distribution, excluding NaN (Not a Number) values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "0pPrOacYw9u1",
        "outputId": "da05f9a2-b293-4328-9ff0-f3652dd3a225"
      },
      "outputs": [],
      "source": [
        "concrete_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ont7fgoCw9u2"
      },
      "source": [
        "### Check if data has any null or missing values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CqUDiUUw9u2",
        "outputId": "8024f64e-ae96-43a1-fcc9-a8549f587799"
      },
      "outputs": [],
      "source": [
        "concrete_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCgF_Ucw9u3"
      },
      "source": [
        "### Define Predictors X and target y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoYpCaevw9u3"
      },
      "outputs": [],
      "source": [
        "concrete_data_columns = concrete_data.columns\n",
        "X = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all independent variables\n",
        "y = concrete_data['Strength'] # depenedent variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TdmTlJQw9u3"
      },
      "source": [
        "### Normalize the dataset of the predictors X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HNi2St9ww9u3",
        "outputId": "2d5a80f7-0920-4c69-e883-1a05c3c27076"
      },
      "outputs": [],
      "source": [
        "X_norm = (X - X.mean()) / X.std() # normalize predictors\n",
        "X_norm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW3TFZXF2fNe"
      },
      "source": [
        "### Randomly split the data into a training and test sets by holding 30% of the data for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zDU60kV2oZn"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=np.random.randint(1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfqVaO-ew9u3"
      },
      "source": [
        "### Define a Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkOE58TUw9u4"
      },
      "outputs": [],
      "source": [
        "n_cols =  X_norm.shape[1] #no of columns\n",
        "def regression_baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    # add 1st 10 hidden layers with the ReLU activation function\n",
        "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
        "    # add 2nd 10 hidden layers with the ReLU activation function\n",
        "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
        "    # add 3rd hidden layers with the ReLU activation function\n",
        "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
        "    # add one output layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T80u_8yw9u4"
      },
      "source": [
        "### Train and evaluate the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZomZJC_gw9u4",
        "outputId": "d419b651-8635-4f38-e904-d6d124ac8f35"
      },
      "outputs": [],
      "source": [
        "mse_list = []\n",
        "for _ in range(50):\n",
        "\n",
        "    # Build the model\n",
        "    regressionModel = regression_baseline_model()\n",
        "\n",
        "    # Train the model\n",
        "    regressionModel.fit(X_train, y_train, epochs=50, verbose=0)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = regressionModel.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_list.append(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msmsQswGw9u4"
      },
      "source": [
        "### Reporting the mean and the standard deviation of the mean squared errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8H6rX8cw9u5",
        "outputId": "10c8b255-554e-421d-d8e7-3a7418b4e462"
      },
      "outputs": [],
      "source": [
        "# get the mean of all mean squared averages\n",
        "mean_mse = np.mean(mse_list);\n",
        "# get the standard deviation of all mean squared averages\n",
        "std_mse = np.std(mse_list);\n",
        "print(f\"Mean of MSEs: {mean_mse}\")\n",
        "print(f\"Standard Deviation of MSEs: {std_mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Difference of Mean Squared Errors of Part B an Part D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part B reported\n",
        "Mean of MSEs: 343.3055146429499\n",
        "while Part D reported Mean of MSEs: 131.21695955595726\n",
        "\n",
        "Increased Complexity: Adding more hidden layers to a neural network increases its complexity, allowing it to learn more intricate patterns in the data. This often leads to better performance, especially if the underlying relationships in the data are complex.\n",
        "\n",
        "Risk of Overfitting: While more complex models can perform better on the training data, there's also a risk of overfitting, where the model learns patterns specific to the training data that don't generalize well to new, unseen data. However, in your case, the improved performance on test data suggests that overfitting was not a significant issue.\n",
        "\n",
        "Consistency of Performance: The reduced standard deviation with three hidden layers suggests that this model is more robust to the variability in the data splits, likely due to its enhanced ability to capture underlying data patterns.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
